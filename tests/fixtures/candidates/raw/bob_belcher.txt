BOB BELCHER
Phone: (555) 123-4567 bob.belcher@bobsburgers.com www.linkedin.com/in/bob-belcher/
Ocean City, New Jersey
PROFESSIONAL SUMMARY
● Over 7+ years of experience in data science, delivering end-to-end ML and AI solutions and
conducting applied research across banking, insurance, and recruitment sectors.
● Designed and deployed cloud-based machine learning and optimization solutions using AWS
SageMaker and Azure ML, supporting scalable model development, CI/CD workflows, and
decision automation in enterprise banking environments.
● Experienced in leveraging Large Language Models (LLMs) and domain-specific fine-tuning using
cloud platforms such as AWS, Azure, and Google Cloud to build secure, scalable AI solutions for
enterprise use.
● Experienced in handling sensitive and confidential information while developing AI solutions and
working with Large Language Models (LLMs), ensuring compliance with data security and privacy
standards.
● Built forecasting models with up to 96% accuracy to predict intern demand and employee
performance using regression, classification, and ensemble techniques, with full lifecycle
ownership including model design, retraining, debugging, and monitoring.
● Led NLP-based projects including chatbots, resume screening tools, and sentiment analysis using
techniques like Word2Vec, TF-IDF, and LSTM, translating open-ended domain questions into
practical AI tools.
● Developed customer segmentation, fraud detection, and recommender systems using clustering,
Random Forests, SVMs, and collaborative filtering, utilizing Scikit-learn for model development
and validation.
● Created interactive web apps and executive-ready dashboards using Dash, Dataiku, Tableau,
Power BI, and Matplotlib to simulate FTE allocation scenarios with live employee and market
data and support decision making.
● Built internal artificial intelligence tools adopted across cycles, replacing inefficient processes
and earning trust among business users through actionable and explainable outputs.
● Designed AI solutions with explainability and model risk as core design principles, incorporating
adversarial testing, causal inference, and stakeholder validation.
● Skilled in handling large-scale, multi-source data with SQL (Teradata, SQL Server, MySQL) and
applying statistical techniques for insights.
● Proven ability to manage multiple projects independently while collaborating with
cross-functional teams to drive results.
● Strong interpersonal and communication skills, with a track record of building productive
relationships and serving as a subject matter expert (SME) across technical and business
stakeholder groups.
● Active volunteer and Hackathon Lead with Women in AI Canada, where I organize national
hackathons focused on AI for social impact, while continuously upskilling in emerging
technologies to stay at the forefront of innovation.
SKILLS
● PROGRAMMING: Python(advanced,production-level), Java, SQL(Teradata, SQL Server, MySQL), R
● MACHINE LEARNING & AI: Logistic & Linear Regression, XGBoost, Decision Trees, Random
Forests, Ensemble Models, Support Vector Machines, K-Nearest Neighbors, Gradient Boost,
Naïve Bayes, A/B Testing, Clustering (K-Means, Hierarchical, DBSCAN), Recommender Systems,
Gaussian Mixtures, PCA, Association Rules, Feature Engineering, Model Lifecycle Management
(training, debugging, retraining, deployment)
● NATURAL LANGUAGE PROCESSING: TF-IDF, Word2Vec, Doc2Vec, FastText, LSTM, Text
Classification, Named Entity Recognition (NER), Semantic Similarity, Q&A Systems, Topic
Modelling (LDA), Adversarial Testing, Explainability (SHAP, DoWhy)
● GENERATIVE AI: Large Language Models (LLM) like Meta Llama, Google Gemma, etc. Prompt
Engineering, Domain-Specific Training
● DEEP LEARNING FRAMEWORKS: TensorFlow, Keras, PyTorch
● DATA VISUALIZATION & APPS: Dash, Tableau, Power BI, Matplotlib, Seaborn, Microsoft Excel
● TOOLS & PLATFORMS: Jupyter Notebook, Dataiku (Certified – Core, ML, MLOps), Scikit-learn,
Azure Databricks, Azure Synapse, AWS SageMaker, Pega Data Science (PCDS), GIT, RStudio,
PyCharm, Visual Studio
● CLOUD TECHNOLOGIES: Azure (ML, Synapse, Databricks), AWS (SageMaker, Lambda, S3),
Dataiku, IBM Watson, Google Cloud Platform
● DATABASES: SQL Server, MySQL, Teradata
● METHODOLOGIES: Agile, Waterfall, Test-Driven Development (TDD), Behaviour-Driven
Development (BDD), MLOps
WORK EXPERIENCE
RBC - Toronto, Ontario, Canada July 2022 - Present
Role: Data Scientist - Advanced
Business Financial Services (BFS), Private Banking (PB), Retail Banking & Accelerating Market
Performance (AMP)
At RBC, I have led several data science and optimization initiatives across BFS, PB, Retail Banking and
AMP, supporting strategic workforce planning, intern forecasting, market prioritization, and performance
modeling through end-to-end solutions.
Responsibilities:
● Designed and deployed end-to-end data science and optimization solutions across BFS, PB, Retail
Banking and AMP, supporting strategic workforce planning, intern forecasting, banker
performance, and client segmentation.
● Fine-tuned domain-specific Large Language Models (LLMs) using company datasets, policy
documents, and project metadata to enable secure and accurate internal knowledge retrieval for
employees.
● Led end-to-end deployment of generative AI tools for internal use, including data preparation,
model training, evaluation, and stakeholder feedback integration, while ensuring sensitive
information was protected and the model was securely hosted within the company’s network.
● Implemented MLOps pipelines in Dataiku and Azure to monitor, retrain, and schedule production
models, ensuring sustained alignment with business goals and shifts in legal or strategic
expectations.
● Partnered with business teams to scope ambiguous problems, define modeling needs, and guide
non-technical stakeholders through design and deployment decisions.
● Built capacity distribution models using geospatial and economic data (e.g., Stats Canada) to
surface market opportunities and rank regions; these served as key inputs to BFS, PB and Retail
Banking optimization frameworks.
● Engineered and implemented combinatorial optimization models using linear programming
(Python’s PuLP) to allocate FTEs by role, span of control, and market constraints, automating
national workforce planning logic.
● Utilized SageMaker pipelines for model tuning, validation, and version control, ensuring
consistent performance and seamless integration with strategic planning workflows.
● Leveraged Azure Databricks to scale data preprocessing workflows and perform distributed
model training for workforce optimization projects across Private Banking and BFS.
● Built and deployed a Dash web app and executive dashboards (Power BI, scenario heatmaps)
integrated with live forecasting and optimization models, enabling real-time workforce planning
and strategy reviews by business leaders.
● Developed teaming models for PB and BFS to recommend FTE support and credit capacity,
incorporating client interaction patterns, borrowing behavior, and NCA targets.
● Conducted adversarial testing and synthetic validations to ensure model robustness across
fragmented data and edge cases, reducing risk and building stakeholder trust.
● Presented model risks, assumptions, and explainability outputs to executives via dashboards and
walkthroughs to ensure alignment with strategic expectations.
● Built scalable data pipelines using SQL (Teradata, SQL Server) and Azure Synapse to transform
large multi-source datasets for forecasting and banker performance modeling, leveraging time
series data and exploring signal, image, and video processing to support broader AI capabilities.
● Applied causal inference (DoWhy) and sensitivity analysis (SALib: variance-based, FAST, Sobol’) to
identify key drivers, evaluate interventions, and enhance model interpretability.
Cognizant - Toronto, Ontario, Canada Jan 2019 – June 2022
Role: Data Scientist - Machine Learning
Roles & Responsibilities:
● Delivered full-cycle machine learning solutions, ranging from data acquisition and preprocessing
to model training and deployment, across recruitment, insurance, and banking sectors, using
Python for modeling and Java for backend integration and scalable deployment.
● Led Natural Language Understanding (NLU) initiatives, including interview competency
assessment, resume evaluation tools, and chatbot development, using NLP techniques like
TF-IDF, Word2Vec, Doc2Vec, FastText, and Bag-of-Words.
● Developed candidate-facing NLP tools using Q&A modeling and text classification to improve
automation, reduce support load, and enhance user alignment.
● Built predictive models for insurance claims and fraud detection using regression, decision trees,
and SVMs to support risk mitigation and operational efficiency.
● Designed collaborative filtering and KNN-based policy recommendation systems to optimize
product offerings and pricing strategies.
● Conducted sentiment analysis on customer and social media data using LSTM, tokenization, PCA,
and topic modeling (LDA).
● Built and validated interpretable ML models with cross-validation and metrics like Precision,
Recall, and F1 Score to ensure robust performance in production.
● Developed interactive dashboards and visual reports using Tableau, Power BI, and Matplotlib to
share actionable insights with stakeholders.
● Facilitated knowledge sharing through internal presentations and data storytelling tailored to
non-technical business audiences.
Infosys – Telangana, India
Role: Data Scientist - Insights & Analytics Jan 2018 - Dec 2018
Roles & Responsibilities:
● Conducted exploratory data analysis on large banking datasets to uncover client behavior trends
and market patterns using Python (Pandas, Seaborn) and Excel.
● Designed customer segmentation models using K-Means clustering and built fraud detection
models with Decision Trees and Random Forests to improve campaign ROI and reduce financial
risk.
● Performed sentiment analysis on customer feedback using NLP techniques such as PCA,
tokenization, and LSTM to assess satisfaction with digital services.
● Created dashboards and reports using Tableau, Power BI, and Matplotlib to communicate
insights on customer behavior and fraud risks to stakeholders.
● Gained foundational experience in model validation, stakeholder communication, and
collaborative solution development under the guidance of senior data scientists.
VOLUNTEER EXPERIENCE
Women in AI Canada - Toronto, Ontario, Canada Jul 2023 - Present
Role: Hackathon Lead - Organizer, Speaker, Mentor, Community Builder
Roles & Responsibilities:
● Honored as the Women in AI Community Catalyst of the Year at the WAI Awards North America
2025 for leadership in AI awareness, community engagement, and inclusive innovation.
● Led the flagship Women in AI Canada Hackathons (2023 & 2024) with 100+ participants annually,
achieving 80–85% women participation, 95% mentor satisfaction, and multiple real-world
solution spin-offs.
● Organized and delivered 7+ technical workshops annually on AI ethics, real-world use cases, and
career development, while mentoring aspiring data scientists and supporting startup incubation.
● Designed technical challenges and mentorship frameworks centered on AI for social impact and
aligned with the World Economic Forum’s Fourth Industrial Revolution for the Earth and DEI
principles.
● Recruited and coordinated 50+ mentors and judges across both years to ensure expert guidance
and robust evaluation.
● Represented WAI as a speaker at the Global AI Summit 2024 and was featured in initiatives like
“A Day in the Life of a Woman in AI,” while also leading stakeholder engagement and securing
sponsorships (e.g., Mia AI, FIRST Robotics Canada).
CERTIFICATIONS
Completed the full suite of five Dataiku certifications: Core Designer, Advanced Designer, ML Practitioner,
MLOps Practitioner, and Developer.
EDUCATION
Bachelor’s degree in engineering - Jawaharlal Nehru Technological University, Kakinada 2014 - 2018
